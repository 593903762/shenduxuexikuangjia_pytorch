{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 autograd\n",
    "\n",
    "用Tensor训练网络很方便，但从上一小节最后的线性回归例子来看，反向传播过程需要手动实现。这对于像线性回归等较为简单的模型来说，还可以应付，但实际使用中经常出现非常复杂的网络结构，此时如果手动实现反向传播，不仅费时费力，而且容易出错，难以检查。torch.autograd就是为方便用户使用，而专门开发的一套自动求导引擎，它能够根据输入和前向传播过程自动构建计算图，并执行反向传播。\n",
    "\n",
    "计算图(Computation Graph)是现代深度学习框架如PyTorch和TensorFlow等的核心，其为高效自动求导算法——反向传播(Back Propogation)提供了理论支持，了解计算图在实际写程序过程中会有极大的帮助。本节将涉及一些基础的计算图知识，但并不要求读者事先对此有深入的了解。关于计算图的基础知识推荐阅读Christopher Olah的文章[^1]。\n",
    "\n",
    "[^1]: http://colah.github.io/posts/2015-08-Backprop/\n",
    "\n",
    "\n",
    "### 3.2.1 requires_grad\n",
    "PyTorch在autograd模块中实现了计算图的相关功能，autograd中的核心数据结构是Variable。从v0.4版本起，Variable和Tensor合并。我们可以认为需要求导(requires_grad)的tensor即Variable. autograd记录对tensor的操作记录用来构建计算图。\n",
    "\n",
    "Variable提供了大部分tensor支持的函数，但其不支持部分`inplace`函数，因这些函数会修改tensor自身，而在反向传播中，variable需要缓存原来的tensor来计算反向传播梯度。如果想要计算各个Variable的梯度，只需调用根节点variable的`backward`方法，autograd会自动沿着计算图反向传播，计算每一个叶子节点的梯度。\n",
    "\n",
    "`variable.backward(gradient=None, retain_graph=None, create_graph=None)`主要有如下参数：\n",
    "\n",
    "- grad_variables：形状与variable一致，对于`y.backward()`，grad_variables相当于链式法则${dz \\over dx}={dz \\over dy} \\times {dy \\over dx}$中的$\\textbf {dz} \\over \\textbf {dy}$。grad_variables也可以是tensor或序列。\n",
    "- retain_graph：反向传播需要缓存一些中间结果，反向传播之后，这些缓存就被清空，可通过指定这个参数不清空缓存，用来多次反向传播。\n",
    "- create_graph：对反向传播过程再次构建计算图，可通过`backward of backward`实现求高阶导数。\n",
    "\n",
    "上述描述可能比较抽象，如果没有看懂，不用着急，会在本节后半部分详细介绍，下面先看几个例子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dir(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0782, -1.3159,  0.4476, -0.9037],\n",
       "        [-0.0113,  2.7013,  0.6741, -0.2403],\n",
       "        [ 1.5332, -0.4542,  0.2728,  1.3497]], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#在创建tensor的时候指定requires_grad\n",
    "a = t.randn(3,4, requires_grad=True)\n",
    "# 或者\n",
    "a = t.randn(3,4).requires_grad_()\n",
    "# 或者\n",
    "a = t.randn(3,4)\n",
    "a.requires_grad=True\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]], requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = t.zeros(3,4).requires_grad_()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0782, -1.3159,  0.4476, -0.9037],\n",
       "        [-0.0113,  2.7013,  0.6741, -0.2403],\n",
       "        [ 1.5332, -0.4542,  0.2728,  1.3497]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 也可写成c = a + b\n",
    "c = a.add(b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = c.sum()\n",
    "d.backward() # 反向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9751, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(d) # d还是一个requires_grad=True的tensor,对它的操作需要慎重\n",
    "d.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d = sum(a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 此处虽然没有指定c需要求导，但c依赖于a，而a需要求导，\n",
    "# 因此c的requires_grad属性会自动设为True\n",
    "a.requires_grad, b.requires_grad, c.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 由用户创建的variable属于叶子节点，对应的grad_fn是None\n",
    "a.is_leaf, b.is_leaf, c.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qin/anaconda3/envs/torch1_env/lib/python3.6/site-packages/torch/tensor.py:746: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  warnings.warn(\"The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad \"\n"
     ]
    }
   ],
   "source": [
    "# c.grad是None, 因c不是叶子节点，它的梯度是用来计算a的梯度\n",
    "# 所以虽然c.requires_grad = True,但其梯度计算完之后即被释放\n",
    "print(c.grad is None)\n",
    "print(c.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算下面这个函数的导函数：\n",
    "$$\n",
    "y = x^2\\bullet e^x\n",
    "$$\n",
    "它的导函数是：\n",
    "$$\n",
    "{dy \\over dx} = 2x\\bullet e^x + x^2 \\bullet e^x\n",
    "$$\n",
    "来看看autograd的计算结果与手动求导计算结果的误差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    '''计算y'''\n",
    "    y = x**2 * t.exp(x)\n",
    "    return y\n",
    "\n",
    "def gradf(x):\n",
    "    '''手动求导函数'''\n",
    "    dx = 2*x*t.exp(x) + x**2*t.exp(x)\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.6693e-04, 2.4916e-01, 2.1633e-01, 1.6129e+00],\n",
       "        [2.2703e-01, 7.5972e+01, 1.6158e-01, 3.9543e-02],\n",
       "        [2.6511e-01, 2.5901e-01, 1.7628e+00, 2.3237e-01]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.randn([3,4], requires_grad = True)\n",
    "y = f(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.0312e-02, -4.4981e-01, -4.5889e-01,  5.4712e+00],\n",
       "        [ 1.3862e+00,  1.3678e+02, -4.5774e-01,  4.7505e-01],\n",
       "        [-4.4312e-01, -4.4584e-01,  5.8500e+00, -4.5527e-01]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward(t.ones(y.size())) # gradient形状与y一致\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.0312e-02, -4.4981e-01, -4.5889e-01,  5.4712e+00],\n",
       "        [ 1.3862e+00,  1.3678e+02, -4.5774e-01,  4.7505e-01],\n",
       "        [-4.4312e-01, -4.4584e-01,  5.8500e+00, -4.5527e-01]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# autograd的计算结果与利用公式手动计算的结果一致\n",
    "gradf(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradf(x) == x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 计算图\n",
    "\n",
    "PyTorch中`autograd`的底层采用了计算图，计算图是一种特殊的有向无环图（DAG），用于记录算子与变量之间的关系。一般用矩形表示算子，椭圆形表示变量。如表达式$ \\textbf {z = wx + b}$可分解为$\\textbf{y = wx}$和$\\textbf{z = y + b}$，其计算图如图3-3所示，图中`MUL`，`ADD`都是算子，$\\textbf{w}$，$\\textbf{x}$，$\\textbf{b}$即变量。\n",
    "\n",
    "![图3-3:computation graph](imgs/com_graph.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如上有向无环图中，$\\textbf{X}$和$\\textbf{b}$是叶子节点（leaf node），这些节点通常由用户自己创建，不依赖于其他变量。$\\textbf{z}$称为根节点，是计算图的最终目标。利用链式法则很容易求得各个叶子节点的梯度。\n",
    "$${\\partial z \\over \\partial b} = 1,\\space {\\partial z \\over \\partial y} = 1\\\\\n",
    "{\\partial y \\over \\partial w }= x,{\\partial y \\over \\partial x}= w\\\\\n",
    "{\\partial z \\over \\partial x}= {\\partial z \\over \\partial y} {\\partial y \\over \\partial x}=1 * w\\\\\n",
    "{\\partial z \\over \\partial w}= {\\partial z \\over \\partial y} {\\partial y \\over \\partial w}=1 * x\\\\\n",
    "$$\n",
    "而有了计算图，上述链式求导即可利用计算图的反向传播自动完成，其过程如图3-4所示。\n",
    "\n",
    "![图3-4：计算图的反向传播](imgs/com_graph_backward.svg)\n",
    "\n",
    "\n",
    "在PyTorch实现中，autograd会随着用户的操作，记录生成当前variable的所有操作，并由此建立一个有向无环图。用户每进行一个操作，相应的计算图就会发生改变。更底层的实现中，图中记录了操作`Function`，每一个变量在图中的位置可通过其`grad_fn`属性在图中的位置推测得到。在反向传播过程中，autograd沿着这个图从当前变量（根节点$\\textbf{z}$）溯源，可以利用链式求导法则计算所有叶子节点的梯度。每一个前向传播操作的函数都有与之对应的反向传播函数用来计算输入的各个variable的梯度，这些函数的函数名通常以`Backward`结尾。下面结合代码学习autograd的实现细节。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = t.ones(1)\n",
    "b = t.rand(1, requires_grad = True)\n",
    "w = t.rand(1, requires_grad = True)\n",
    "y = w * x # 等价于y=w.mul(x)\n",
    "z = y + b # 等价于z=y.add(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True, True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.requires_grad, b.requires_grad, w.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 虽然未指定y.requires_grad为True，但由于y依赖于需要求导的w\n",
    "# 故而y.requires_grad为True\n",
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.is_leaf, w.is_leaf, b.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.is_leaf, z.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AddBackward0 at 0x7fcc23d412e8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grad_fn可以查看这个variable的反向传播函数，\n",
    "# z是add函数的输出，所以它的反向传播函数是AddBackward，因为z是由y和b相加得到\n",
    "# z = y + b\n",
    "z.grad_fn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<MulBackward0 at 0x7fcc23d86ef0>, 0),\n",
       " (<AccumulateGrad at 0x7fcc23d86e80>, 0))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next_functions保存grad_fn的输入，是一个tuple，tuple的元素也是Function\n",
    "# z = y + b\n",
    "# 第一个是y，它是乘法(mul)的输出，所以对应的反向传播函数y.grad_fn是MulBackward\n",
    "# 第二个是b，它是叶子节点，由用户创建，grad_fn为None，但是有\n",
    "z.grad_fn.next_functions \n",
    "\n",
    "# z = y + b\n",
    "# y =  w * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MulBackward0 at 0x7fcc23d86ef0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AddBackward0 at 0x7fcc23d412e8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<MulBackward0 at 0x7fcc23d86ef0>, 0),\n",
       " (<AccumulateGrad at 0x7fcc23d86e80>, 0))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.grad_fn.next_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<MulBackward0 at 0x7fcc23d86ef0>, 0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.grad_fn.next_functions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MulBackward0 at 0x7fcc23d86ef0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.grad_fn.next_functions[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variable的grad_fn对应着和图中的function相对应\n",
    "z.grad_fn.next_functions[0][0] == y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<AccumulateGrad at 0x7fcc23d415c0>, 0), (None, 0))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = wx\n",
    "# 第一个是w，叶子节点，需要求导，梯度是累加的\n",
    "# 第二个是x，叶子节点，不需要求导，所以为None\n",
    "y.grad_fn.next_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 叶子节点的grad_fn是None\n",
    "w.grad_fn,x.grad_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算w的梯度的时候，需要用到x的数值(${\\partial y\\over \\partial w} = x $)，这些数值在前向过程中会保存成buffer，在计算完梯度之后会自动清空。为了能够多次反向传播需要指定`retain_graph`来保留这些buffer。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用retain_graph来保存buffer\n",
    "z.backward(retain_graph=True)\n",
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 多次反向传播，梯度累加，这也就是w中AccumulateGrad标识的含义\n",
    "z.backward()\n",
    "w.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch使用的是动态图，它的计算图在每次前向传播时都是从头开始构建，所以它能够使用Python控制语句（如for、if等）根据需求创建计算图。这点在自然语言处理领域中很有用，它意味着你不需要事先构建所有可能用到的图的路径，图在运行时才构建。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def abs(x):\n",
    "    if x.data[0]>0: return x\n",
    "    else: return -x\n",
    "x = t.ones(1,requires_grad=True)\n",
    "y = abs(x)\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.])\n"
     ]
    }
   ],
   "source": [
    "x = -1*t.ones(1)\n",
    "x = x.requires_grad_()\n",
    "y = abs(x)  # y = -x\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.], grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.], requires_grad=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.])\n"
     ]
    }
   ],
   "source": [
    "x = t.tensor([-1.0] )\n",
    "x = x.requires_grad_()\n",
    "y = abs(x)\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.requires_grad\n",
    "cc=x*3\n",
    "cc.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 6., 3., 2.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x):\n",
    "    result = 1\n",
    "    for ii in x:\n",
    "        if ii.item()>0: \n",
    "            result=ii*result\n",
    "    return result\n",
    "x = t.arange(-2,4,dtype=t.float32).requires_grad_() # [-2,-1,0,1,2,3]\n",
    "y = f(x) # y = x[3]*x[4]*x[5]\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "变量的`requires_grad`属性**默认为False**，如果某一个节点requires_grad被设置为True，那么所有依赖它的节点`requires_grad`都是True。这其实很好理解，对于$ \\textbf{x}\\to \\textbf{y} \\to \\textbf{z}$，x.requires_grad = True，当需要计算$\\partial z \\over \\partial x$时，根据链式法则，$\\frac{\\partial z}{\\partial x} = \\frac{\\partial z}{\\partial y} \\frac{\\partial y}{\\partial x}$，自然也需要求$ \\frac{\\partial z}{\\partial y}$，所以y.requires_grad会被自动标为True. \n",
    "\n",
    "\n",
    "\n",
    "有些时候我们可能不希望autograd对tensor求导。认为求导需要缓存许多中间结构，增加额外的内存/显存开销，那么我们可以关闭自动求导。对于不需要反向传播的情景（如inference，即测试推理时），关闭自动求导可实现一定程度的速度提升，并节省约一半显存，因其不需要分配空间计算梯度。\n",
    "\n",
    "\n",
    "如果不希望autograd对tensor求导，就可以把tensor封装在一个with结构当中：\n",
    "```python\n",
    "with t.no_grad():\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.ones(1, requires_grad=True)\n",
    "w = t.rand(1, requires_grad=True)\n",
    "y = x * w\n",
    "# y依赖于w，而w.requires_grad = True\n",
    "x.requires_grad, w.requires_grad, y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True, False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with t.no_grad():\n",
    "    x = t.ones(1)\n",
    "    w = t.rand(1, requires_grad = True)\n",
    "    y = x * w\n",
    "# y依赖于w和x，虽然w.requires_grad = True，但是y的requires_grad依旧为False\n",
    "x.requires_grad, w.requires_grad, y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.no_grad??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True, False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.set_grad_enabled(False)\n",
    "x = t.ones(1)\n",
    "w = t.rand(1, requires_grad = True)\n",
    "y = x * w\n",
    "# y依赖于w和x，虽然w.requires_grad = True，但是y的requires_grad依旧为False\n",
    "x.requires_grad, w.requires_grad, y.requires_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fcc1c28f588>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 恢复默认配置\n",
    "t.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们想要修改tensor的数值，但是又不希望被autograd记录，那么我么可以对tensor.data进行操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = t.ones(3,4,requires_grad=True)\n",
    "b = t.ones(3,4,requires_grad=True)\n",
    "c = a * b\n",
    "\n",
    "a.data # 还是一个tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.data.requires_grad # 但是已经是独立于计算图之外"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7311, 0.7311, 0.7311, 0.7311],\n",
      "        [0.7311, 0.7311, 0.7311, 0.7311],\n",
      "        [0.7311, 0.7311, 0.7311, 0.7311]])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "d = a.data.sigmoid_() # sigmoid_ 是个inplace操作，会修改a自身的值\n",
    "print(d)\n",
    "print(d.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7311, 0.7311, 0.7311, 0.7311],\n",
       "        [0.7311, 0.7311, 0.7311, 0.7311],\n",
       "        [0.7311, 0.7311, 0.7311, 0.7311]], requires_grad=True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们希望对tensor，但是又不希望被记录, 可以使用tensor.data 或者tensor.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 近似于 tensor=a.data, 但是如果tensor被修改，backward可能会报错\n",
    "tensor = a.detach()\n",
    "tensor.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7311, 0.7311, 0.7311, 0.7311],\n",
      "        [0.7311, 0.7311, 0.7311, 0.7311],\n",
      "        [0.7311, 0.7311, 0.7311, 0.7311]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计tensor的一些指标，不希望被记录\n",
    "mean = tensor.mean()\n",
    "std = tensor.std()\n",
    "maximum = tensor.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.7311, 0.7311, 0.7311, 0.7311],\n",
      "        [0.7311, 0.7311, 0.7311, 0.7311]])\n"
     ]
    }
   ],
   "source": [
    "tensor[0]=1\n",
    "print(tensor)\n",
    "# 下面会报错：　RuntimeError: one of the variables needed for gradient\n",
    "#             computation has been modified by an inplace operation\n",
    "#　因为 c=a*b, b的梯度取决于a，现在修改了tensor中的tensor[0]，其实也就是修改了a(近似修改了a.data)，梯度不再准确\n",
    "# c.sum().backward() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在反向传播过程中非叶子节点的导数计算完之后即被清空。若想**查看这些变量的梯度**，有两种方法：\n",
    "- 使用autograd.grad函数\n",
    "- 使用hook\n",
    "\n",
    "`autograd.grad`和`hook`方法都是很强大的工具，更详细的用法参考官方api文档，这里举例说明基础的使用。推荐使用`hook`方法，但是在实际使用中应尽量避免修改grad的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.ones(3, requires_grad=True)\n",
    "w = t.rand(3, requires_grad=True)\n",
    "y = x * w\n",
    "# y依赖于w，而w.requires_grad = True\n",
    "z = y.sum()\n",
    "x.requires_grad, w.requires_grad, y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.5858, 0.3485, 0.0451]), tensor([1., 1., 1.]), None)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 非叶子节点grad计算完之后自动清空，y.grad是None\n",
    "z.backward()\n",
    "(x.grad, w.grad, y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1.]),)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第一种方法：使用grad获取中间变量的梯度\n",
    "x = t.ones(3, requires_grad=True)\n",
    "w = t.rand(3, requires_grad=True)\n",
    "y = x * w\n",
    "z = y.sum()\n",
    "# z对y的梯度，隐式调用backward()\n",
    "t.autograd.grad(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y的梯度： tensor([1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# 第二种方法：使用hook\n",
    "# hook是一个函数，输入是梯度，不应该有返回值\n",
    "def variable_hook(grad):\n",
    "    print('y的梯度：',grad)\n",
    "\n",
    "x = t.ones(3, requires_grad=True)\n",
    "w = t.rand(3, requires_grad=True)\n",
    "y = x * w\n",
    "# 注册hook\n",
    "hook_handle = y.register_hook(variable_hook)\n",
    "z = y.sum()\n",
    "z.backward()\n",
    "\n",
    "# 除非你每次都要用hook，否则用完之后记得移除hook\n",
    "hook_handle.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后再来看看variable中grad属性和backward函数`grad_variables`参数的含义，这里直接下结论：\n",
    "\n",
    "- variable $\\textbf{x}$的梯度是目标函数${f(x)} $对$\\textbf{x}$的梯度，$\\frac{df(x)}{dx} = (\\frac {df(x)}{dx_0},\\frac {df(x)}{dx_1},...,\\frac {df(x)}{dx_N})$，形状和$\\textbf{x}$一致。\n",
    "- 对于y.backward(grad_variables)中的grad_variables相当于链式求导法则中的$\\frac{\\partial z}{\\partial x} = \\frac{\\partial z}{\\partial y} \\frac{\\partial y}{\\partial x}$中的$\\frac{\\partial z}{\\partial y}$。z是目标函数，一般是一个标量，故而$\\frac{\\partial z}{\\partial y}$的形状与variable $\\textbf{y}$的形状一致。`z.backward()`在一定程度上等价于y.backward(grad_y)。`z.backward()`省略了grad_variables参数，是因为$z$是一个标量，而$\\frac{\\partial z}{\\partial z} = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 3., 8.], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = t.arange(0,3, requires_grad=True,dtype=t.float) # 【0，1，2】\n",
    "y = x**2 + x*2  #【0， 3， 8】\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = y.sum()  # y1 + y2 + y3  \n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于在第一个位置 $x_1$,  $z = y_1 + y_2 + y_3$, $z$ 对其 $x_1$ 求导， $\\frac{dz}{dx_1} = \\frac{d(y_1 + y_2 + y_3)}{dx_1} = \\frac{dy_1}{dx_1} = 2x_1 + 2 $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 4., 6.])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.backward() # 从z开始反向传播\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 4., 6.])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.arange(0,3, requires_grad=True,dtype=t.float)\n",
    "y = x**2 + x*2\n",
    "z = y.sum()\n",
    "y_gradient = t.Tensor([1,1,1]) # dz/dy\n",
    "y.backward(y_gradient) #从y开始反向传播\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外值得注意的是，只有对variable的操作才能使用autograd，如果对variable的data直接进行操作，将无法使用反向传播。除了对参数初始化，一般我们不会修改variable.data的值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在PyTorch中计算图的特点可总结如下：\n",
    "\n",
    "- autograd根据用户对variable的操作构建其计算图。对变量的操作抽象为`Function`。\n",
    "- 对于那些不是任何函数(Function)的输出，由用户创建的节点称为叶子节点，叶子节点的`grad_fn`为None。叶子节点中需要求导的variable，具有`AccumulateGrad`标识，因其梯度是累加的。\n",
    "- variable默认是不需要求导的，即`requires_grad`属性默认为False，如果某一个节点requires_grad被设置为True，那么所有依赖它的节点`requires_grad`都为True。\n",
    "- variable的`volatile`属性默认为False，如果某一个variable的`volatile`属性被设为True，那么所有依赖它的节点`volatile`属性都为True。volatile属性为True的节点不会求导，volatile的优先级比`requires_grad`高。\n",
    "- 多次反向传播时，梯度是累加的。反向传播的中间缓存会被清空，为进行多次反向传播需指定`retain_graph`=True来保存这些缓存。\n",
    "- 非叶子节点的梯度计算完之后即被清空，可以使用`autograd.grad`或`hook`技术获取非叶子节点的值。\n",
    "- variable的grad与data形状一致，应避免直接修改variable.data，因为对data的直接操作无法利用autograd进行反向传播\n",
    "- 反向传播函数`backward`的参数`grad_variables`可以看成链式求导的中间结果，如果是标量，可以省略，默认为1\n",
    "- PyTorch采用动态图设计，可以很方便地查看中间层的输出，动态的设计计算图结构。\n",
    "\n",
    "这些知识不懂大多数情况下也不会影响对pytorch的使用，但是掌握这些知识有助于更好的理解pytorch，并有效的避开很多陷阱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 扩展autograd\n",
    "\n",
    "\n",
    "目前绝大多数函数都可以使用`autograd`实现反向求导，但如果需要自己写一个复杂的函数，不支持自动反向求导怎么办? 写一个`Function`，实现它的前向传播和反向传播代码，`Function`对应于计算图中的矩形， 它接收参数，计算并返回结果。下面给出一个例子。\n",
    "\n",
    "```python\n",
    "\n",
    "class Mul(Function):\n",
    "                                                            \n",
    "    @staticmethod\n",
    "    def forward(ctx, w, x, b, x_requires_grad = True):\n",
    "        ctx.x_requires_grad = x_requires_grad\n",
    "        ctx.save_for_backward(w,x)\n",
    "        output = w * x + b\n",
    "        return output\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        w,x = ctx.saved_tensors\n",
    "        grad_w = grad_output * x\n",
    "        if ctx.x_requires_grad:\n",
    "            grad_x = grad_output * w\n",
    "        else:\n",
    "            grad_x = None\n",
    "        grad_b = grad_output * 1\n",
    "        return grad_w, grad_x, grad_b, None\n",
    "```\n",
    "\n",
    "分析如下：\n",
    "\n",
    "- 自定义的Function需要继承autograd.Function，没有构造函数`__init__`，forward和backward函数都是静态方法\n",
    "- backward函数的输出和forward函数的输入一一对应，backward函数的输入和forward函数的输出一一对应\n",
    "- backward函数的grad_output参数即t.autograd.backward中的`grad_variables`\n",
    "- 如果某一个输入不需要求导，直接返回None，如forward中的输入参数x_requires_grad显然无法对它求导，直接返回None即可\n",
    "- 反向传播可能需要利用前向传播的某些中间结果，需要进行保存，否则前向传播结束后这些对象即被释放\n",
    "\n",
    "Function的使用利用Function.apply(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "class MultiplyAdd(Function):\n",
    "                                                            \n",
    "    @staticmethod\n",
    "    def forward(ctx, w, x, b):                              \n",
    "        ctx.save_for_backward(w,x)\n",
    "        output = w * x + b\n",
    "        return output\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):                         \n",
    "        w,x = ctx.saved_tensors\n",
    "        grad_w = grad_output * x\n",
    "        grad_x = grad_output * w\n",
    "        grad_b = grad_output * 1\n",
    "        return grad_w, grad_x, grad_b                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, tensor([1.]), tensor([1.]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.ones(1)\n",
    "w = t.rand(1, requires_grad = True)\n",
    "b = t.rand(1, requires_grad = True)\n",
    "# 开始前向传播\n",
    "z=MultiplyAdd.apply(w, x, b)\n",
    "# 开始反向传播\n",
    "z.backward()\n",
    "\n",
    "# x不需要求导，中间过程还是会计算它的导数，但随后被清空\n",
    "x.grad, w.grad, b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.]), tensor([0.5979], grad_fn=<MulBackward0>), tensor([1.]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.ones(1)\n",
    "w = t.rand(1, requires_grad = True)\n",
    "b = t.rand(1, requires_grad = True)\n",
    "#print('开始前向传播')\n",
    "z=MultiplyAdd.apply(w,x,b)\n",
    "#print('开始反向传播')\n",
    "\n",
    "# 调用MultiplyAdd.backward\n",
    "# 输出grad_w, grad_x, grad_b\n",
    "z.grad_fn.apply(t.ones(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之所以forward函数的输入是tensor，而backward函数的输入是variable，是为了实现高阶求导。backward函数的输入输出虽然是variable，但在实际使用时autograd.Function会将输入variable提取为tensor，并将计算结果的tensor封装成variable返回。在backward函数中，之所以也要对variable进行操作，是为了能够计算梯度的梯度（backward of backward）。下面举例说明，有关torch.autograd.grad的更详细使用请参照文档。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10.], grad_fn=<MulBackward0>),)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.tensor([5], requires_grad=True,dtype=t.float)\n",
    "y = x ** 2\n",
    "grad_x = t.autograd.grad(y, x, create_graph=True)\n",
    "grad_x # dy/dx = 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2.]),)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_grad_x = t.autograd.grad(grad_x[0],x)\n",
    "grad_grad_x # 二阶导数 d(2x)/dx = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这种设计虽然能让`autograd`具有高阶求导功能，但其也限制了Tensor的使用，因autograd中反向传播的函数只能利用当前已经有的Variable操作。这个设计是在`0.2`版本新加入的，为了更好的灵活性，也为了兼容旧版本的代码，PyTorch还提供了另外一种扩展autograd的方法。PyTorch提供了一个装饰器`@once_differentiable`，能够在backward函数中自动将输入的variable提取成tensor，把计算结果的tensor自动封装成variable。有了这个特性我们就能够很方便的使用numpy/scipy中的函数，操作不再局限于variable所支持的操作。但是这种做法正如名字中所暗示的那样只能求导一次，它打断了反向传播图，不再支持高阶求导。\n",
    "\n",
    "\n",
    "上面所描述的都是新式Function，还有个legacy Function，可以带有`__init__`方法，`forward`和`backwad`函数也不需要声明为`@staticmethod`，但随着版本更迭，此类Function将越来越少遇到，在此不做更多介绍。\n",
    "\n",
    "此外在实现了自己的Function之后，还可以使用`gradcheck`函数来检测实现是否正确。`gradcheck`通过数值逼近来计算梯度，可能具有一定的误差，通过控制`eps`的大小可以控制容忍的误差。\n",
    "关于这部份的内容可以参考github上开发者们的讨论[^3]。\n",
    "\n",
    "[^3]: https://github.com/pytorch/pytorch/pull/1016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面举例说明如何利用Function实现sigmoid Function。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Function):\n",
    "                                                             \n",
    "    @staticmethod\n",
    "    def forward(ctx, x): \n",
    "        output = 1 / (1 + t.exp(-x))\n",
    "        ctx.save_for_backward(output)\n",
    "        return output\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output): \n",
    "        output,  = ctx.saved_tensors\n",
    "        grad_x = output * (1 - output) * grad_output\n",
    "        return grad_x                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 采用数值逼近方式检验计算梯度的公式对不对\n",
    "test_input = t.randn(3,4, requires_grad=True).double()\n",
    "t.autograd.gradcheck(Sigmoid.apply, (test_input,), eps=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325 µs ± 7.84 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "314 µs ± 16.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "138 µs ± 7.42 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "def f_sigmoid(x):\n",
    "    y = Sigmoid.apply(x)\n",
    "    y.backward(t.ones(x.size()))\n",
    "    \n",
    "def f_naive(x):\n",
    "    y =  1/(1 + t.exp(-x))\n",
    "    y.backward(t.ones(x.size()))\n",
    "    \n",
    "def f_th(x):\n",
    "    y = t.sigmoid(x)\n",
    "    y.backward(t.ones(x.size()))\n",
    "    \n",
    "x=t.randn(100, 100, requires_grad=True)\n",
    "%timeit -n 100 f_sigmoid(x)\n",
    "%timeit -n 100 f_naive(x)\n",
    "%timeit -n 100 f_th(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "显然`f_sigmoid`要比单纯利用`autograd`加减和乘方操作实现的函数快不少，因为f_sigmoid的backward优化了反向传播的过程。另外可以看出系统实现的built-in接口(t.sigmoid)更快。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 小试牛刀: 用Variable实现线性回归\n",
    "在上一节中讲解了利用tensor实现线性回归，在这一小节中，将讲解如何利用autograd/Variable实现线性回归，以此感受autograd的便捷之处。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机数种子，为了在不同人电脑上运行时下面的输出一致\n",
    "t.manual_seed(1000) \n",
    "\n",
    "def get_fake_data(batch_size=8):\n",
    "    ''' 产生随机数据：y = x*2 + 3，加上了一些噪声'''\n",
    "    x = t.rand(batch_size,1) * 5\n",
    "    y = x * 2 + 3 + t.randn(batch_size, 1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fcc16099eb8>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 来看看产生x-y分布是什么样的\n",
    "x, y = get_fake_data()\n",
    "plt.scatter(x.squeeze().numpy(), y.squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2030582427978516 3.0900990962982178\n"
     ]
    }
   ],
   "source": [
    "# 随机初始化参数\n",
    "w = t.rand(1,1, requires_grad=True)\n",
    "b = t.zeros(1,1, requires_grad=True)\n",
    "losses = np.zeros(500)\n",
    "\n",
    "lr =0.005 # 学习率\n",
    "\n",
    "for ii in range(500):\n",
    "    x, y = get_fake_data(batch_size=32)\n",
    "    \n",
    "    # forward：计算loss\n",
    "    y_pred = x.mm(w) + b.expand_as(y)\n",
    "    loss = 0.5 * (y_pred - y) ** 2\n",
    "    loss = loss.sum()\n",
    "    losses[ii] = loss.item()\n",
    "    \n",
    "    # backward：手动计算梯度\n",
    "    loss.backward()\n",
    "    \n",
    "    # 更新参数\n",
    "    w.data.sub_(lr * w.grad.data)\n",
    "    b.data.sub_(lr * b.grad.data)\n",
    "    \n",
    "    # 梯度清零\n",
    "    w.grad.data.zero_()\n",
    "    b.grad.data.zero_()\n",
    "    \n",
    "    if ii%50 ==0:\n",
    "        # 画图\n",
    "        \n",
    "        x2, y2 = get_fake_data(batch_size=20) \n",
    "        display.clear_output(wait=True)\n",
    "        x = t.arange(0, 6).view(-1, 1).float()\n",
    "        y = x.mm(w.data) + b.data.expand_as(x)\n",
    "        plt.plot(x.numpy(), y.numpy()) # predicted\n",
    "#         y = x2.mm(w.data) + b.data.expand_as(x2)\n",
    "#         plt.plot(x2.numpy(), y.numpy()) # predicted\n",
    "        \n",
    "        \n",
    "        plt.title('the epoch is {%d}' % ii)\n",
    "        plt.scatter(x2.numpy(), y2.numpy()) # true data\n",
    "        \n",
    "        plt.xlim(0,5)\n",
    "        plt.ylim(0,13)   \n",
    "        plt.show()\n",
    "        plt.pause(0.5)\n",
    "        \n",
    "print(w.item(), b.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.0, 50.0)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.ylim(5,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用autograd实现的线性回归最大的不同点就在于autograd不需要计算反向传播，可以自动计算微分。这点不单是在深度学习，在许多机器学习的问题中都很有用。另外需要注意的是在每次反向传播之前要记得先把梯度清零。\n",
    "\n",
    "本章主要介绍了PyTorch中两个基础底层的数据结构：Tensor和autograd中的Variable。Tensor是一个类似Numpy数组的高效多维数值运算数据结构，有着和Numpy相类似的接口，并提供简单易用的GPU加速。Variable是autograd封装了Tensor并提供自动求导技术的，具有和Tensor几乎一样的接口。`autograd`是PyTorch的自动微分引擎，采用动态计算图技术，能够快速高效的计算导数。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
